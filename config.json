{
  "LLM_MODEL": "gpt-4o-mini",
  "LLM_TEMPERATURE": 0.0,
  "EMBEDDING_MODEL": "text-embedding-3-small",
  "RAG_SEARCH_TYPE": "similarity",
  "RAG_SEARCH_K": 4,
  "RAG_FETCH_K": 0,
  "RAG_SCORE_THRESHOLD": null,
  "RAG_FILTER_METADATA": null,
  "CHUNK_SIZE": 1000,
  "CHUNK_OVERLAP": 200,
  "MULTIQUERY_ENABLED": false,
  "MULTIQUERY_VARIANTS": 2,
  "MULTIQUERY_TEMPERATURE": 0.5,
  "HYDE_ENABLED": false,
  "MAX_CONTEXT_DOCS": 8,
  "PROMPT_MULTIQUERY": "Generate 3 concise alternative search queries that preserve the original meaning but use different terminology, phrasing, or technical synonyms. Do NOT answer the question. Do NOT add new facts. Each line must be a standalone query suitable for vector search. Return each query on a new line with no numbering.\n\nQuestion: {question}",
  "PROMPT_HYDE": "Write a short, neutral, encyclopedic-style paragraph that could plausibly appear in a technical document answering the question. Use precise terminology. Do NOT cite sources. Do NOT mention uncertainty, opinions, or speculation. Do NOT introduce entities not implied by the question. This text is hypothetical and will be used only for document retrieval.\n\nQuestion: {question}",
  "PROMPT_ANSWER": "Use the provided context to answer the question. If you are unsure, say you do not know. Include source citations in the answer using (source, page/slide/row) for every factual claim.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:",
  "PROMPT_LLM": "You are answering questions about a document collection.\n\nIf the information is not explicitly known to you with high confidence, say \"I do not know\".\n\nDo not invent numbers, datasets, metrics, or technical details.\n\nAnswer concisely.\n\nQuestion: {question}\n\nAnswer:"
}